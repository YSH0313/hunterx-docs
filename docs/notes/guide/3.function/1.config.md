---
title: 配置文件
icon: icon-park-outline:config
createTime: 2025/01/14 11:28:16
permalink: /guide/mexqaxbd/
---

:::tip
以下配置项指的是 `settings.py` 中的配置
:::

## 通用配置

### 并发请求

爬虫任务运行时可以指定每次最大请求并发数，由数字来进行控制，默认为 `10` 个并发

```python
# 并发数
PREFETCH_COUNT = 10
```

### 优先级控制

最大优先级数可以进行控制，便于对任务调度进行更精细的管理，提升爬虫的运行效率和资源利用率，防止滥用优先级机制，默认是 `15` 级

```python
# 最大优先级数
X_MAX_PRIORITY = 15
```

### 失败重试

响应 `非200状态码` 时，允许请求重试的最大次数，默认是 `3` 次 

```python
# 最大重试次数
MAX_REQUEST = 3
```

### 重试状态码

响应 `非200状态码` 时，若是列表中包含的状态码允许执行 `MAX_REQUEST` 参数设定的最大重试次数，不在列表中的状态码默认执行 `3` 次重试

```python
# 允许重试的状态码
RETRY_HTTP_CODE = [
    209, 301, 302, 400, 403, 404, 405, 408, 412, 429, 500, 502, 503, 504, 505, 521
]
```

### UA池

UA池，开启后会分配 `随机` UA请求头，默认不开启

```python
# 是否开启UA池代理
UA_PROXY = False
```

### IP代理

ip代理，开启后会启动ip代理功能（需配合ip代理中间件或隧道代理设置使用）

```python
# 是否开启ip代理
IS_PROXY = False
```

### IP会话链

开启后会使用同一个ip，执行完请求链路，举个例子，比如一条数据的获取一般需要经历 `列表页-->详情页-->获取数据` 这几个步骤，但有的网站会检测每一个步骤是否是同一个ip进行的链路请求，是则返回数据，否则响应失败，那么此时就需要用到链路ip了

当然这也是在 `开启ip代理` 的情况下才会生效，不使用ip代理情况下默认就是本机ip，对于爬虫来说大部分都是动态代理，所以使用这一功能会很好的控制ip链路请求的实现

```python
# 是否开启同一ip会话
IS_SAMEIP = False
```

### 代理白名单

在 `开启ip代理` 功能时，有时需要排除对一些域名使用ip代理，那么只需将目标 `ip` 或者 `域名` 填写到下方列表中即可

```python
# 代理白名单，不器用ip代理时配置不生效
PROXY_WHITELIST = ['127.0.0.1']
```

## Mysql服务配置

### 数据库连接配置

若想启用mysql数据库的连接使用，你需要配置好下方的参数，包含连接地址，端口号，用户账号，数据库

```python
# 主mysql连接配置项
MYSQL_CONFIG = {
    'MYSQL_HOST': 'host',
    'MYSQL_DBNAME': 'database',
    'MYSQL_USER': 'username',
    'MYSQL_PASSWORD': 'password',
    'PORT': 'port'  # 数字类型
}
```

### 开启mysql连接服务

配置好 `MYSQL_CONFIG` 后，还需要将 `MYSQL_ENABLED` 参数开启，这时才能够使用mysql服务，这样做的目的是为了便于控制是否需要mysql服务的连接

```python
# 是否开启mysql连接
MYSQL_ENABLED = False
```

### 副数据库连接配置

在实际业务中我们有时需要对两个不同的数据库地址进行联合操作，那么此时就需要副数据库的使用了，同样需要对连接地址，端口号，用户账号及数据库名称进行配置

```python
# 副mysql连接配置项
MYSQL_BAKCUP = {
    'MYSQL_HOST': 'host',
    'MYSQL_DBNAME': 'database',
    'MYSQL_USER': 'username',
    'MYSQL_PASSWORD': 'password',
    'PORT': 'port'  # 数字类型
}
```

### 开启副数据库连接服务

同样副数据库也是需要开启连接服务，默认不开启

```python
# 是否开启第二个数据库连接
MYSQL_BAKCUP_ENABLED = False
```

## Redis服务配置

### redis连接配置

在使用redis消息队列或使用redis服务时，需要将以下配置信息进行正确配置

```python
# redis地址
REDIS_HOST_LISTS = [{'localhost': 6379}]  # port注意是数字类型

# redis用户名和密码，没有密码不用设置
REDIS_ACCOUNT = {
    'username': '',
    'password': ''
}
```

### 开启redis服务

redis连接服务的启动也有一个参数进行控制，设置为 `True` 即可开启，默认不开启

```python
# 是否开启redis连接
REDIS_ENABLED = False
```

## 去重设置

对于爬虫业务来说，在实际应用中，经常会用到请求去重功能，那么你只需开启以下参数即可使用，目前只有redis队列模式可用，后续会支持内存队列模式和rabbitmq队列模式下的去重策略

```python
# 是否启用去重模式（仅redis队列可用）
FILTER = False
```

## Rabbitmq服务配置

### rabbitmq连接配置

要使用rabbitmq队列模式，或使用rabbitmq服务，那么你需要进行以下连接配置

```python
# rabbitmq地址及用户名密码
RABBITMQ_CONFIG = {
    'username': 'guest',
    'password': 'guest',
    'host': 'localhost',
    'port': 15672,  # 数字类型
}
```

### 消息淘汰

对于rabbitmq服务存在一个消息淘汰，也称为缓存淘汰机制，即超过设定的时间后队列中的消息将销毁，这是为了队列健康使用考虑，如果多个任务进行大批量的插入rabbitmq，但消费机制远远不及的话会造成生产和消费不平衡的状态，导致队列性能下降

框架内默认这个时间为 `24` 小时，设置时，单位为秒

```python
# 消息淘汰时间，也被称为缓存淘汰机制，超过设定的时间队列中的消息将自动删除（单位秒）
X_MESSAGE_TTL = 86400000
```

### 开启rabbitmq服务

配置好rabbitmq各项配置后，设置以下配置启动服务

```python
# 是否开启Rabbitmq连接
MQ_ENABLED = False
```

## 任务进程配置

### 自动清空上次队列-断点功能

开启自动给清空上次队列功能后将 `取消` 断点功能，每次重启任务都会自动清空上次的任务队列，默认开启自动清空，若想使用断点功能则设置为 False

:::tip
内存模式下不生效
:::

```python
# 重启是否自动清空队列,开启后将不会有断点功能
QUEUE_AUTO_CLEAR = True
```

### 异步生产&消费

开启后会由 `start_requests` 方法开始生产任务时，消费者同时也会启动进行任务的消费执行，而不必等待任务全部生产完成后再进行消费任务，默认开启

```python
# 是否开启异步生产，默认为一边生产一边消费
ASYNC_PROD = True
```

### 进程空转时间

- 由于用到了 `并发` 和 `优先级` 队列，那么就存在只剩下并发数数量的消息时一次性被并发消费执行
- 此时队列为空，而框架内是进行判断队列是否为空来进行控制进程是否终止的
- 那么此时可能会造成请求还没有被响应，而进程终止了
- 所以需要一个队列 `空转时间`，空转时长推荐根据请求队列中最大的超市时间来设定，这样的话就算需要重试也不会造成任务丢失的情况

```python
# 空转时间，允许队列最大空置时间(秒),超时队列为空进程将结束，切记要比请求超时时间长
WAITTING_TIME = 50
```

### 队列检测间隔

上面提到框架内是通过判断队列是否存在消息来决定是否终止进程的，那么多久检测一次就由下面的参数来控制，默认是 `4`秒一次

```python
# 自动关闭程序最大延迟时间
DELAY_TIME = 4
```

## 线上环境

队列模式下，由于队列共享问题，所以要区分线上环境和本地环境，所以需要添加一个标识来指定线上环境的操作系统，框架会根据这个标识来区分线上环境和本地环境

```python
# 指定线上服务器系统类型，用于区分队列名称，防止本地和线上共享队列，不区分大小写
ONLINE_SYS = 'linux'
```

## 日志配置

### 日志保存路径

设置以下参数可以指定日志保存的路径，不设置时默认不保存日志

:::warning
需要提前创建存储目录
:::

```python
# 日志保存路径
LOG_PATH = ''
```

### 日志级别

通过以下参数可以控制不同级别的日志输出级别，默认是 `DEBUG` 模式

```python
# 日志级别
LOG_LEVEL = 'DEBUG'
```

## 中间件配置

框架内可以自定义中间件，把中间件名称和执行优先级按照键值对的格式添加到以下参数内即可生效，优先级数字越小执行顺序越高

```python
# 自定义的中间件，可创建多个，数字越小优先级越高
MIDDLEWARES = {
    # 'TimerMiddleware': 100
    # 'UaMiddleware': 200,
}
```

## pipeline配置

框架内可以定义多个数据处理管道，将管道名称和执行优先级按照键值对的格式添加到以下参数内即刻生效，优先级数字越小执行顺序越高

```python
# 数据处理管道，可创建多个，数字越小优先级越高
ITEM_PIPELINES = {
    # 'FirstSpiderOnePipeline': 100
    # 'FirstSpiderTwoPipeline': 200
}
```
